{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from utils import *\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib as mpl\n",
    "## agg backend is used to create plot as a .png file\n",
    "#mpl.use('agg')\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"response_time_max\"\n",
    "dataset = \"baseline40-80-jan2022.csv\"\n",
    "sdataset = \"hiccup-no-stiffle-40-80v1.csv\"\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spadata = \"spadata.csv\"\n",
    "spadatablob = \"spadata-blob.csv\"\n",
    "spadatatrucks = \"spadata-empty-semi-trucks.csv\"\n",
    "spadataexpensive = \"spadata-expensive-db.csv\"\n",
    "spadatastifle = \"spadata-stifle.csv\"\n",
    "spadatajam = \"spadata-traffic-jam.csv\"\n",
    "spadatacont = \"spadata-continuous.csv\"\n",
    "spadatahic = \"spadata-hiccups.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_outliers(anomaly_counter):\n",
    "    \"\"\"We label as outliner only the rows with anomaly_counter equals to -1\"\"\"\n",
    "    if anomaly_counter == -1:\n",
    "        return \"Outlier\" \n",
    "    else: \n",
    "        return \"Inliner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_baseline(mean, std):\n",
    "    \"\"\"We multiply by 0.6 assuming that the system without queuing has a mean response time 60% lower (T = mean * (1-load))\"\"\"\n",
    "    return (mean+3*std)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_counters(counter, baseline):\n",
    "    \"\"\"We compare a measurement with the baseline of a given counter\"\"\"\n",
    "    if counter >= baseline:\n",
    "        return \"Fail\" \n",
    "    else:\n",
    "        return \"Pass\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bstatistic_df = pd.read_csv(dataset)\n",
    "statistic_df = pd.read_csv(sdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_df = pd.read_csv(spadata)\n",
    "spablob_df = pd.read_csv(spadatablob)\n",
    "spatrucks_df = pd.read_csv(spadatatrucks)\n",
    "spaexpensive_df = pd.read_csv(spadataexpensive)\n",
    "spastifle_df = pd.read_csv(spadatastifle)\n",
    "spajam_df = pd.read_csv(spadatajam)\n",
    "spacont_df = pd.read_csv(spadatacont)\n",
    "spahic_df = pd.read_csv(spadatahic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bstatistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spablob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatrucks_df\n",
    "#spaexpensive_df\n",
    "#spastifle_df\n",
    "#spajam_df\n",
    "#spacont_df\n",
    "spahic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for load in lb_detection_df.load.unique():\n",
    " #   if (load == 90):\n",
    "       # for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "figure = plt.figure\n",
    "ax = plt.gca()\n",
    "#ax.scatter(spa_df['ndistance'], spa_df['slope'], color='red')\n",
    "\n",
    "\n",
    "ax.scatter(spablob_df['ndistance'], spablob_df['Slope'], color='blue',label='the blob')\n",
    "ax.scatter(spatrucks_df['ndistance'], spatrucks_df['Slope'], color='green',label='empty semi trucks')\n",
    "ax.scatter(spaexpensive_df['ndistance'], spaexpensive_df['Slope'], color='red',label='expensive db calls')\n",
    "ax.scatter(spastifle_df['ndistance'], spastifle_df['Slope'], color='purple',label='the stifle')\n",
    "ax.scatter(spajam_df['ndistance'], spajam_df['Slope'], color='orange',label='traffic jam')\n",
    "ax.scatter(spacont_df['ndistance'], spacont_df['Slope'], color='black',label='continuous violated requirements')\n",
    "ax.scatter(spahic_df['ndistance'], spahic_df['Slope'], color='magenta',label='application hiccups')\n",
    "ax.set_xlabel(' normalized distance > 1 failed performance requirement baseline')\n",
    "ax.set_ylabel('slope > 0.1 failed scalability trend')\n",
    "ax.set_ylim(-10,550)\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "#plt.legend()\n",
    "#ax.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1, loc='upper left')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05),\n",
    "          ncol=2, fancybox=True, shadow=True)\n",
    "#plt.show()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for load in lb_detection_df.load.unique():\n",
    " #   if (load == 90):\n",
    "       # for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "figure = plt.figure\n",
    "ax = plt.gca()\n",
    "ax.scatter(spa_df['ndistance'], spa_df['slope'], color='red')\n",
    "\n",
    "\n",
    "ax.set_xlabel(' normalized distance > 1 failed performance requirement baseline')\n",
    "ax.set_ylabel('slope > 0.1 failed scalability trend')\n",
    "ax.set_ylim(-10,400)\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "\n",
    "\n",
    "#plt.show()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution (probability of S)\n",
    "bstatistic_df[\"load\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability of a giving load\n",
    "load_probabilities_df = pd.DataFrame(bstatistic_df.groupby(['load']).instance.count().rename(\"load_probability\"))\n",
    "load_probabilities_df.load_probability /= load_probabilities_df.load_probability.sum()\n",
    "lstatistic_df = pd.merge(bstatistic_df, load_probabilities_df, left_on=['load'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of executing any of the operations by summing up all operations as \n",
    "# the denominator and the operation counter as the numerator\n",
    "probabilities_df = pd.DataFrame(lstatistic_df.groupby(['counter_name']).instance.count().rename(\"activation_probability\"))\n",
    "#probabilities_df = pd.DataFrame(probabilities_df/probabilities_df.groupby(level=[0, 1]).transform(\"sum\"))\n",
    "probabilities_df.activation_probability /= probabilities_df.activation_probability.sum()\n",
    "probabilities_df = probabilities_df.reset_index()\n",
    "lstatistic_df = pd.merge(lstatistic_df, probabilities_df, on=['counter_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline calculation and assessment - base statistics\n",
    "assessment_df = pd.DataFrame(bstatistic_df.groupby(['counter_name'])[metric].agg(['mean', 'std']))\n",
    "assessment_df['baseline'] = assessment_df.apply(lambda x: calc_baseline(x[\"mean\"], x[\"std\"]), axis=1)\n",
    "#statistics_df = pd.merge(statistic_df.groupby(['counter_name'])[metric].agg(['mean', 'std']))\n",
    "statistic_df = pd.merge(statistic_df, assessment_df[['baseline']], \n",
    "                        left_on='counter_name', right_index=True).reset_index(drop=True)\n",
    "statistic_df[\"assessment\"] = statistic_df.apply(lambda x: eval_counters(x[metric], x[\"baseline\"]), axis=1)\n",
    "statistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fraction of successful service execution * the probability activation of the services\n",
    "s_df = lstatistic_df.groupby(['load', 'load_probability', 'counter_name', 'activation_probability']).instance.count().rename(\"s\")\n",
    "s_df = pd.DataFrame(s_df/s_df.groupby(level=[0, 1, 2]).transform(\"sum\"))\n",
    "s_df = s_df.reset_index()\n",
    "#s_df = s_df[s_df.assessment == 'Pass'].sort_values(['load','s'], ascending=[True, False]).reset_index(drop=True)\n",
    "#s_df = s_df.drop(columns=['assessment'])\n",
    "groupby_dict = {\"activation_probability\":\"s\", \n",
    "           \"s\":\"s\"} \n",
    "s_df = s_df.set_index(['load', 'load_probability', 'counter_name'])\n",
    "s_df = s_df.groupby(groupby_dict, axis = 1).prod().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add analysis timestamp\n",
    "statistic_df['analysis_timestamp'] = dt.datetime.today()\n",
    "#domain_metric_df['analysis_timestamp'] = dt.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "lb_detection_df = statistic_df.copy()\n",
    "lb_detection_df['anomaly'] = pd.Series()\n",
    "assessment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to use baseline from bstatistics and max from statistics\n",
    "#baseline is from bstatistics to metrics is from statistics\n",
    "df=pd.DataFrame(statistic_df.groupby(['counter_name','load']).agg({metric:'max','baseline':'mean'}))\n",
    "df.columns.name=None\n",
    "df=df.reset_index()\n",
    "df['distance'] = df.baseline - df[metric]\n",
    "df['ndistance'] = 2*df[metric]/(df.baseline+df[metric])\n",
    "df['assessment'] = df.distance.apply(lambda x: False if (x>0) else True)\n",
    "df['binary'] = df.distance.apply(lambda x: 0 if (x>0) else 1)\n",
    "\n",
    "bs_df=pd.DataFrame(df.groupby(['counter_name']).binary.sum())\n",
    "\n",
    "df = pd.merge(df, bs_df, on=\"counter_name\")\n",
    "df = df.rename(columns={\"binary_x\":\"binary\", \"binary_y\":\"sbinary\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#measurement < baseline ndistance -> 0, measurement = baseline ndistance = 0.5\n",
    "#measurement >> baseline ndistance -> 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_df.binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute slope and concatenate to df\n",
    "#create slope df\n",
    "slope_df = df.copy()\n",
    "slope_df['slope'] = pd.Series()\n",
    "for service in lb_detection_df.counter_name.unique():\n",
    "    for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "        x = lb_detection_df.loc[(lb_detection_df.counter_name == counter), 'load']\n",
    "        y = lb_detection_df.loc[(lb_detection_df.counter_name == counter), metric]\n",
    "        b = lb_detection_df.loc[(lb_detection_df.counter_name == counter), 'baseline']\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        #degree = 2\n",
    "        #coeffs = np.polyfit(x, y, degree)\n",
    "        # now, coeffs is an array which contains the polynomial coefficients\n",
    "        # in ascending order, i.e. x^0, x^1, x^2\n",
    "        #print('1:ndistance\\\\' + str(slope_df.loc[(lb_detection_df.counter_name == counter), 'ndistance']))\n",
    "        #intercept1, linear, quadratic = coeffs\n",
    "        slope_df.loc[(slope_df.counter_name == counter), 'slope'] = slope\n",
    "        #print('2:slope\\\\' + str(slope_df.loc[(lb_detection_df.counter_name == counter), 'slope']))\n",
    "        \n",
    "        #slope_df.loc[(slope_df.counter_name == counter), 'quad'] = quadratic\n",
    "        #print('2:ndistance' + str(slope_df.loc[(lb_detection_df.counter_name == counter), 'ndistance']))\n",
    "slope_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope_df.loc[slope_df.load == 90,['counter_name','ndistance','slope', 'sbinary']].to_csv('eo.csv',index=False)\n",
    "slope_df.loc[slope_df.load == 80,['counter_name','ndistance','slope']].to_csv('edb-slope_nd20.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_80_df = slope_df.loc[slope_df.load == 80,['counter_name','ndistance','slope']]\n",
    "meas_80_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_meas_80_df = slope_df.loc[slope_df.load == 80,['ndistance','slope','counter_name','assessment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.scatter(meas_80_df['ndistance'], meas_80_df['slope'], color='blue')\n",
    "ax.set_xlabel(' normalized distance > 1 failed performance requirement baseline, load = 40%')\n",
    "ax.set_ylabel('slope > 0.1 failed scalability trend')\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "    #plt.legend()\n",
    "#plt.show()\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meas_90_df['slope']/meas_90_df['slope'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spa_t_df['slope']/spa_t_df['slope'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot with vertical lines per SPA\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.scatter(meas_80_df['ndistance'], (meas_80_df['slope']/meas_80_df['slope'].max()), color='blue')\n",
    "\n",
    "\n",
    "ax.set_xlabel(' normalized distance > 1 failed performance requirement baseline, load = 80%')\n",
    "ax.set_ylabel('nomalized slope')\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "\n",
    "# Prepare data for training\n",
    "spa_t_df = spa_df.copy()\n",
    "spa_t_df['index'] = pd.Series()\n",
    "max=spa_t_df['slope'].max()\n",
    "plt.axvline(spa_t_df['ndistance'][0], color='magenta',label=spa_t_df['spa'][0]) \n",
    "plt.axvline(spa_t_df['ndistance'][1], color='purple',label=spa_t_df['spa'][1])\n",
    "plt.axvline(spa_t_df['ndistance'][2], color='green',label=spa_t_df['spa'][2])\n",
    "plt.axvline(spa_t_df['ndistance'][3], color='yellow',label=spa_t_df['spa'][3])\n",
    "plt.axvline(spa_t_df['ndistance'][4], color='blue',label=spa_t_df['spa'][4])\n",
    "plt.axvline(spa_t_df['ndistance'][5], color='orange',label=spa_t_df['spa'][5])\n",
    "plt.axvline(spa_t_df['ndistance'][6], color='red',label=spa_t_df['spa'][6])\n",
    "plt.axhline((spa_t_df['slope'][0]/spa_t_df['slope'].max()), color='magenta') \n",
    "plt.axhline((spa_t_df['slope'][1]/spa_t_df['slope'].max()), color='purple')\n",
    "plt.axhline((spa_t_df['slope'][2]/spa_t_df['slope'].max()), color='green')\n",
    "plt.axhline((spa_t_df['slope'][3]/spa_t_df['slope'].max()), color='yellow')\n",
    "plt.axhline((spa_t_df['slope'][4]/spa_t_df['slope'].max()), color='blue')\n",
    "plt.axhline((spa_t_df['slope'][5]/spa_t_df['slope'].max()), color='orange')\n",
    "plt.axhline((spa_t_df['slope'][6]/spa_t_df['slope'].max()), color='red')\n",
    "#plt.grid()\n",
    "ax.set_ylim(-0.2,1.1)\n",
    "ax.set_xlim(0,2)\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "\n",
    "#ax.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1, loc='upper left')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05),\n",
    "          ncol=2, fancybox=True, shadow=True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot with vertical lines per SPA\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.scatter(meas_80_df['ndistance'], meas_80_df['slope'], color='blue')\n",
    "\n",
    "\n",
    "ax.set_xlabel(' normalized distance > 1 failed performance requirement baseline, load = 90%')\n",
    "ax.set_ylabel('slope > 0.1 failed scalability trend')\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "\n",
    "# Prepare data for training\n",
    "spa_t_df = spa_df.copy()\n",
    "spa_t_df['index'] = pd.Series()\n",
    "max=spa_t_df['slope'].max()\n",
    "plt.axvline(spa_t_df['ndistance'][0], color='magenta',label=spa_t_df['spa'][0]) \n",
    "plt.axvline(spa_t_df['ndistance'][1], color='purple',label=spa_t_df['spa'][1])\n",
    "plt.axvline(spa_t_df['ndistance'][2], color='green',label=spa_t_df['spa'][2])\n",
    "plt.axvline(spa_t_df['ndistance'][3], color='yellow',label=spa_t_df['spa'][3])\n",
    "plt.axvline(spa_t_df['ndistance'][4], color='blue',label=spa_t_df['spa'][4])\n",
    "plt.axvline(spa_t_df['ndistance'][5], color='orange',label=spa_t_df['spa'][5])\n",
    "plt.axhline(spa_t_df['ndistance'][6], color='red',label=spa_t_df['spa'][6])\n",
    "#plt.grid()\n",
    "ax.set_ylim(-30,350)\n",
    "ax.set_xlim(0,2)\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "\n",
    "#ax.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1, loc='upper left')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05),\n",
    "          ncol=2, fancybox=True, shadow=True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for load in lb_detection_df.load.unique():\n",
    " #   if (load == 90):\n",
    "       # for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "figure = plt.figure\n",
    "ax = plt.gca()\n",
    "ax.scatter(slope_df['ndistance'], slope_df['slope'], color='red')\n",
    "ax.set_xlabel(' normalized distance > 1 failed performance requirement baseline')\n",
    "ax.set_ylabel('slope > 0.1 failed scalability trend')\n",
    "        #ax.set_title(\"{} vs {}\".format(x_col, y_col))\n",
    "majorLocator   = MultipleLocator(5)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator   = MultipleLocator(1)\n",
    "    #plt.legend()\n",
    "#plt.show()\n",
    "plt.axhline(0.1,color='black')  #horizontal line\n",
    "plt.axvline(1,color='black')  #vertical line\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.set(style=\"whitegrid\")\n",
    "sns.set()\n",
    "g=sns.relplot(x='ndistance',y='slope',\n",
    "              hue=\"counter_name\",\n",
    "              data=slope_df, style=\"assessment\",col=\"load\")\n",
    "\n",
    "plt.savefig('hiccup-sens20.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_meas_90_df\n",
    "sns.set()\n",
    "sns.relplot(x='ndistance',y='slope',\n",
    "          hue=\"counter_name\", style=\"assessment\",\n",
    "            data=full_meas_80_df,legend=\"full\")\n",
    "plt.savefig('hiccup-40-80load80-0821.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quadratic\n",
    "#for service in lb_detection_df.counter_name.unique():\n",
    "#    for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "#        figure = plt.figure\n",
    "#        ax = plt.gca()\n",
    "#        ax.scatter(slope_df['ndistance'], slope_df['quad'])\n",
    " #       ax.set_xlabel(' normalized distance')\n",
    " #       ax.set_ylabel('quadratic')\n",
    " #   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances and plot slope vs. distance\n",
    "for service in lb_detection_df.counter_name.unique():\n",
    "    for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "        figure = plt.figure\n",
    "        ax = plt.gca()\n",
    "        ax.scatter(slope_df['distance'], slope_df['slope'])\n",
    "        ax.set_xlabel('distance')\n",
    "        ax.set_ylabel('slope')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_distance_df = pd.DataFrame(df.groupby(['counter_name']).assessment.any())\n",
    "failed_distance_df.columns.name=None\n",
    "failed_distance_df=failed_distance_df.reset_index()\n",
    "failed_distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter in failed_distance_df.loc[failed_distance_df.assessment == True,'counter_name'].values:\n",
    "    plt.figure()\n",
    "    x = df.loc[df.counter_name == counter, 'load']\n",
    "    y = df.loc[df.counter_name == counter, metric]\n",
    "    b = df.loc[df.counter_name == counter, 'baseline']\n",
    "    plt.xlabel(str(counter) + ' MAX FAILED ')\n",
    "    plt.scatter(x, y, s=10, color='green')\n",
    "    plt.plot(x,b,color='red',label='baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models (one per counter, load as the second dimension of the anomaly detection process)\n",
    "for service in lb_detection_df.counter_name.unique():\n",
    "    for counter in lb_detection_df.loc[lb_detection_df.counter_name == service, 'counter_name'].unique():\n",
    "        x = lb_detection_df.loc[(lb_detection_df.counter_name == counter), 'load']\n",
    "        y = lb_detection_df.loc[(lb_detection_df.counter_name == counter), metric]\n",
    "        b = lb_detection_df.loc[(lb_detection_df.counter_name == counter), 'baseline']\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        print('counter = ' + str(counter) + ' slope = ' + str(slope))\n",
    "        if (slope < 0.01):\n",
    "            plt.figure()\n",
    "            print('p_value = '+ str(p_value))\n",
    "            print('slope = ' + str(slope))\n",
    "            print('intercept = ' +str(intercept))\n",
    "            print('r_value = ' +str(r_value))\n",
    "            print('std_err = ' +str(std_err))\n",
    "            x = lb_detection_df.loc[(lb_detection_df.counter_name == counter), 'load']\n",
    "            y = lb_detection_df.loc[(lb_detection_df.counter_name == counter), metric]\n",
    "            plt.xlabel(str(counter) + '\\n SLOPE PASS -- p_value = ' + str(p_value) + '   slope = '+ str(slope) + ' r_value = ' + str(r_value))\n",
    "            plt.scatter(x, y, s=10, color='green')\n",
    "            plt.plot(x,b,color='red',label='baseline')\n",
    "\n",
    "        \n",
    "        if (slope >= 0.01): #and (p_value < 0.05):\n",
    "            plt.figure()\n",
    "            x = lb_detection_df.loc[(lb_detection_df.counter_name == counter), 'load']\n",
    "            y = lb_detection_df.loc[(lb_detection_df.counter_name == counter), metric]\n",
    "            plt.xlabel(str(counter) + '\\n SLOPE FAIL p_value = ' + str(p_value) + '   slope = '+ str(slope) + ' r_value = ' + str(r_value))\n",
    "            plt.scatter(x, y, s=10, color='green')\n",
    "            plt.plot(x,b,color='red',label='baseline')\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
